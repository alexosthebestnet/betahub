<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
        body, html { margin: 0; height: 100%; font-family: Arial, sans-serif; background: black; color: white }
        #status-gif { width: 100%; height: auto; }
    </style>
</head>
<body>
    <img id="status-gif" src="bootup.gif" alt="Status">
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            const statusGif = document.getElementById('status-gif');
            let recognition;
            let isRecording = false;
            let wakeWordDetected = false;
            let messageHistory = [{ role: "system", content: "System message content here" }]; // System message
            let currentMessage = '';
            let silenceTimer = null;

            setTimeout(() => { changeGif('normal-state.gif'); }, 3000); // Bootup for 3 seconds

            function initializeSpeechRecognition() {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.lang = 'en-US';
                recognition.interimResults = true;
                recognition.onresult = handleRecognitionResult;
                recognition.onend = restartSpeechRecognition;
                recognition.start();
                resetSilenceTimer();
                console.log("Speech recognition initialized.");
            }

            function restartSpeechRecognition() {
                if (!wakeWordDetected) {
                    recognition.stop();
                    setTimeout(() => {
                        recognition.start();
                        console.log("Speech recognition restarted.");
                    }, 100); // Brief pause before restart
                    resetSilenceTimer();
                }
            }

           function handleRecognitionResult(event) {
    for (let i = event.resultIndex; i < event.results.length; ++i) {
        if (event.results[i][0] && typeof event.results[i][0].transcript === 'string') {
            let transcript = event.results[i][0].transcript.trim().replace(/,/g, "");
            if (event.results[i].isFinal) {
                console.log("Heard:", transcript);
                resetSilenceTimer(); // Reset timer on any final speech detected

                if (transcript.toLowerCase().includes("hey hub")) {
                    wakeWordDetected = true;
                    isRecording = true;
                    let splitTranscript = transcript.toLowerCase().split("hey hub");
                    if (splitTranscript.length > 1) {
                        currentMessage = splitTranscript[1].trim(); // Capture only after "Hey Hub"
                    } else {
                        currentMessage = ""; // Clear message if "Hey Hub" not followed by more speech
                    }
                    changeGif('wake-word-detected.gif');
                    console.log("Wake word detected. Switching to listening mode.");
                } else if (wakeWordDetected) {
                    currentMessage += ' ' + transcript;
                    changeGif('word-spoken.gif');
                    if (isRecording) {
                        setTimeout(sendInputToAPI, 2000); // Send input after 2 seconds of pause
                    }
                }
            }
        }
    }
}


            function sendInputToAPI() {
                isRecording = false;
                changeGif('sending-to-api.gif');
                console.log("Sending to API:", currentMessage);
                messageHistory.push({ role: "user", content: currentMessage });
                if (messageHistory.length > 50) { // Keep last 25 user-assistant pairs
                    messageHistory = messageHistory.slice(-50);
                }

                let token = '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'; // Your API key
                fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer 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` },
                    body: JSON.stringify({ model: "gpt-3.5-turbo", messages: messageHistory })
                })
                .then(response => response.json())
                .then(data => {
                    let aiResponse = data.choices[0].message.content;
                    console.log("API response:", aiResponse);
                    messageHistory.push({ role: "assistant", content: aiResponse });
                    receiveAPIResponse(aiResponse);
                })
                .catch(error => console.error('Error:', error));
            }

            function receiveAPIResponse(response) {
                changeGif('responding.gif');
                speak(response);
                resetState();
            }

            function speak(text) {
                console.log("Speaking:", text);
                const utterance = new SpeechSynthesisUtterance(text);
                window.speechSynthesis.speak(utterance);
            }

            function resetState() {
                wakeWordDetected = false;
                currentMessage = '';
                setTimeout(() => {
                    changeGif('normal-state.gif');
                }, 5000); // Reset state after 5 seconds
            }

            function resetSilenceTimer() {
                clearTimeout(silenceTimer);
                silenceTimer = setTimeout(() => {
                    if (!isRecording) {
                        recognition.stop();
                        setTimeout(() => {
                            recognition.start();
                            changeGif('normal-state.gif');
                            console.log("No speech detected. Resetting.");
                        }, 100);
                    }
                }, 30000); // 30 seconds of silence
            }

            function changeGif(gifName) {
                statusGif.src = gifName;
                console.log("Gif changed to:", gifName);
            }

            initializeSpeechRecognition();
        });
    </script>
</body>
</html>
