<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
        body, html { margin: 0; height: 100%; font-family: Arial, sans-serif; background: black; color: white }
        #status-gif { width: 100%; height: auto; }
    </style>
</head>
<body>
    <img id="status-gif" src="bootup.gif" alt="Status">
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            const statusGif = document.getElementById('status-gif');
            let recognition;
            let wakeWordDetected = false;
            let currentMessage = '';
            let interimTranscript = '';
            let silenceTimer = null;

            setTimeout(() => { changeGif('normal-state.gif'); }, 3000); // Bootup for 3 seconds

            function initializeSpeechRecognition() {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.lang = 'en-US';
                recognition.interimResults = true;
                recognition.onresult = handleRecognitionResult;
                recognition.onend = restartSpeechRecognition;
                recognition.start();
                resetSilenceTimer();
                console.log("Speech recognition initialized.");
            }

            function restartSpeechRecognition() {
                if (!wakeWordDetected) {
                    recognition.stop();
                    setTimeout(() => {
                        recognition.start();
                        console.log("Speech recognition restarted.");
                    }, 100); // Brief pause before restart
                    resetSilenceTimer();
                }
            }

            function handleRecognitionResult(event) {
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    let transcript = event.results[i][0].transcript.trim().replace(/,/g, "");
                    if (event.results[i].isFinal) {
                        console.log("Heard:", transcript);
                        resetSilenceTimer(); // Reset timer on any final speech detected

                        if (wakeWordDetected) {
                            currentMessage = interimTranscript + ' ' + transcript;
                            changeGif('word-spoken.gif');
                            setTimeout(sendInputToAPI, 2000); // Send input after 2 seconds of pause
                            interimTranscript = ''; // Reset interim transcript after processing
                        } else if (transcript.toLowerCase().includes("hey hub")) {
                            wakeWordDetected = true;
                            let splitTranscript = transcript.toLowerCase().split("hey hub");
                            interimTranscript = splitTranscript.length > 1 ? splitTranscript[1].trim() : "";
                            changeGif('https://i.ibb.co/fn40PJm/I-hear-you.gif');
                            console.log("Wake word detected. Switching to listening mode.");
                        }
                    } else if (wakeWordDetected) {
                        interimTranscript += transcript;
                    }
                }
            }

            function sendInputToAPI() {
                wakeWordDetected = false;
                changeGif('https://i.ibb.co/B2JmjJc/Thinking.gif');
                console.log("Sending to API:", currentMessage);
                
                fetch('https://api.deepinfra.com/v1/openai/chat/completions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer HnO6SXFKeKem8tkzRo8f8LAbeWL42F6h` },
                    body: JSON.stringify({ 
                        model: "Gryphe/MythoMax-L2-13b", 
                        messages: [{ role: "system", content: "System message content here" }, { role: "user", content: currentMessage }] 
                    })
                })
                .then(response => response.json())
                .then(data => {
                    let aiResponse = data.choices[0].message.content;
                    console.log("API response:", aiResponse);
                    receiveAPIResponse(aiResponse);
                })
                .catch(error => console.error('Error:', error));
                currentMessage = ''; // Reset currentMessage after sending
            }

            function receiveAPIResponse(response) {
                changeGif('https://i.ibb.co/WxbwbD1/Normal-gif.gif');
                speak(response);
                resetState();
            }

            function speak(text) {
                console.log("Speaking:", text);
                const utterance = new SpeechSynthesisUtterance(text);
                window.speechSynthesis.speak(utterance);
            }

            function resetState() {
                wakeWordDetected = false;
                setTimeout(() => {
                    changeGif('https://i.ibb.co/WxbwbD1/Normal-gif.gif');
                }, 5000); // Reset state after 5 seconds
            }

            function resetSilenceTimer() {
                clearTimeout(silenceTimer);
                silenceTimer = setTimeout(() => {
                    if (!wakeWordDetected) {
                        recognition.stop();
                        setTimeout(() => {
                            recognition.start();
                            changeGif('normal-state.gif');
                            console.log("No speech detected. Resetting.");
                        }, 100);
                    }
                }, 30000); // 30 seconds of silence
            }

            function changeGif(gifName) {
                statusGif.src = gifName;
                console.log("Gif changed to:", gifName);
            }

            initializeSpeechRecognition();
        });
    </script>
</body>
</html>
