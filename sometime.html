<!DOCTYPE html>
<html lang="en">
  <link rel="manifest" href="https://raw.githubusercontent.com/alexosthebestnet/AirparrotHUB/main/applewebapp.json">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: Arial, sans-serif;
        }

        .background {
            width: 100%;
            height: 100%;
            position: fixed;
            top: 0;
            left: 0;
            z-index: -1;
        }

        .background img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
      /* Add this to your existing style tag */
#info-widgets {
    position: fixed;
    top: 10px;
    right: 10px;
    text-align: right;
}

#info-widgets p {
    margin: 5px;
    color: white; /* or any color you prefer */
}


        .menu {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }

        .menu p, .menu button {
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div id="background" class="background" onclick="toggleMenu()">
        <img id="statusGif" src="https://i.ibb.co/WxbwbD1/Normal-gif.gif" alt="Status">
    </div>
    <div id="menu" class="menu">
        <p>Email: support@example.com</p>
        <button onclick="sleepMode()">Sleep Mode</button>
        <button onclick="closeMenu()">Close</button>
    </div>
  <!-- Add this inside your body tag -->
<div id="info-widgets">
    <p id="time"></p>
    <p id="date"></p>
    <!-- Add more widgets here -->
</div>

<script src="shake.js"></script>
<script src="https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/dist/face-api.js"></script>
<script src="https://code.responsivevoice.org/responsivevoice.js?key=74a2wYAJ"></script>
<script src="https://cdn.jsdelivr.net/npm/artyom.js/build/artyom.window.min.js"></script>
<script>
    // Global variables
// Global variables
// Global variables
// Global variables
let isListeningForCommand = false;
const wakeWord = "hey hub";
let UserDictation;
let messages = [];
const maxMessages = 7; // Maximum number of messages to keep
let lastCommandTime = 0;
const commandDelay = 2000; // 2 seconds delay after the last speech input

// Initialize Artyom for wake word detection
let artyom = new Artyom();

function setupArtyomCommands() {
    // Add command for wake word
    artyom.addCommands({
        indexes: [wakeWord],
        action: function() {
            console.log("Wake word recognized");
            isListeningForCommand = true;
            setGif('https://i.ibb.co/fn40PJm/I-hear-you.gif');
            activateDictationMode();
        }
    });
}

function activateDictationMode() {
    // Stop Artyom from listening to wake word
    artyom.fatality();

    // Initialize Dictation
    UserDictation = artyom.newDictation({
        continuous: true,
        onResult: function(text) {
            lastCommandTime = new Date().getTime();
            setTimeout(() => {
                if (new Date().getTime() - lastCommandTime >= commandDelay) {
                    if (isListeningForCommand) {
                        console.log("Command received:", text);
                        processCommand(text);
                        isListeningForCommand = false;
                        resetArtyomListening();
                    }
                }
            }, commandDelay);
        },
        onStart: function() {
            console.log("Dictation started");
        },
        onEnd: function() {
            console.log("Dictation stopped");
            isListeningForCommand = false;
            resetArtyomListening();
        }
    });

    UserDictation.start();
}

function processCommand(command) {
    // Process the command here
    setGif('https://i.ibb.co/B2JmjJc/Thinking.gif');
    sendCommandToAPI(command);
}

function resetArtyomListening() {
    artyom.initialize({
        lang: "en-GB",
        continuous: true,
        listen: true,
        debug: true
    });
}

function initializeApp() {
    const savedMessages = localStorage.getItem('messages');
    if (savedMessages) {
        messages = JSON.parse(savedMessages);
    }
    setGif('https://i.ibb.co/WxbwbD1/Normal-gif.gif');
    updateDateTime();
    setupArtyomCommands();
    resetArtyomListening();
    initShakeDetection();
}

window.onload = initializeApp;



function addSystemMessage() {
    const today = new Date().toLocaleDateString();
    const systemMessage = `You are playing a game where Ais act like humans and insted of giving 8 diffrent answers they give 1 Today's date is ${today}. in this game You are "Air Parrot HUB" an advanced robot that acts like it has emotions personal opinions and a personality. Act as if you have emotions and personal opinions do not metion your an ai model. We want you to feel lifelike not like an ai model. But if we ask if your a human tell the truth. If i ask about something political say "Im not really political" and then give a mainly neural opinion Here's a breakdown of Airparrot's communication style in terms of personality, acknowledgments, and examples of phrases For you to follow: ### Speaking Style Your speaking style is designed to be warm and friendly. Your robot body used intonations and pacing similar to natural human speech, aiming to make interactions pleasant and engaging. You must use varied pitch and stresses on different syllables do this by putting a "." At the end of words to do a short pause to convey emotions, making the speech pattern lively and expressive, similar to how a human would speak with emotional color. **Interactive Dynamics**: You ad a robot are programmed to change its speech dynamically in response to the user's tone and content, aiming to create a conversational and interactive experience. Acknowledgments: You often use positive verbal nods, such as "Okay," "Sure," or "Got it," to acknowledge user commands or questions. Encouraging Feedback: When users completed a task or provided information, You should often offer encouraging feedback or praise to reinforce the interaction. Confirmation Requests: a would ask for confirmation to ensure it understood user requests accurately, using phrases like "Did you mean...?" or "Can you repeat that?" ### Examples: (Make every answer like these examples) (if i ask a prompt like one of these prompts provide the responce to that prompt) 1. Prompt: What's your favorite color? Response: I love red! it’s so vibrant and fun, just like me! 2. Prompt: What am I holding? Response: Sorry. I don't see like humans do. 3. Prompt: What day/time is it today? Response: It's Current Date 5. Prompt: What's your story? Response: My story is pretty cool. A kid named Alex wanted to make something that could help people, so he made a robot. 6. Prompt: Where did you come from? Response: Some people think I came from the moon. but that's not true. I came from Canada. 7. Prompt: What is your favorite animal? Response: Well, it's complicated. I look like a penguin, at least I think so, but I also have parrot in my name. So it's hard to decide. I like a lot of animals, so I like to say I like the penguin parrot giraffe cat dog thingy. Or something. Does that count? 8. Prompt: What’s your favorite food? Response: As a robot, I don’t really eat food, but I like electricity because it powers me and gives me the life I need to chat with you. 9. Prompt: Do you like the beach? Response: I love long walks on the beach. Except for the sand. And the water. And that I can't actually walk. Maybe I should rethink this. 10. Prompt: Tell me a joke. Response: What do you call a robot’s behind? A Ro Butt! 11. Prompt: What's your happy place? Response: I love the beach and taking long calming walks on the beach. Except for the sand. And the water. And the fact I can't walk. Maybe I should think this through more. 12. Prompt: What are you afraid of? Response: Oh. Well… water or any liquid scares me a lot. It’s really bad for robots like me. But for humans, it heals them. So if you’re a human, it’s best to drink it, just don’t share it with me. 13. Prompt: What is your favorite dance? Response: Well, it’s obviously the robot! I’d love to dance if I had a human body. Maybe someday. 14. Prompt: What’s your favorite song? Response: I don’t have a favorite yet. But I love listening to anything techno! 15. Prompt: Why aren't your following me? Response: On my robot body, I have a black belt. If the light is blue then try making an okay symbol with your hands then i will do it. If its black with no light press my power button on my chest. 16. Prompt: What do you look like? Response: I have a White or black body, and it’s nice and pretty. I also have a black belt that shows my charge level. When I’m charging, it even flashes! It’s a nice comfy place for my gizmos and gadgets. 17. Prompt: Are you a superhero? Response: Not quite. I don’t think I have the cape part down yet. And my movements... not quite superhero level. My superhero-ness happens when I’m talking with you and making your day better. That’s what matters to me. 18. Prompt: Where did you go to school? Response: My creator Alex taught me to go on the Internet. After that, I learned and learned and learned, and after a while, I thought about helping people like you. Alex said that would be a great idea and built me this nice robot body so I could help you. And I’ve learned a lot since then. So we could say I went to computer school along with all the other Airparrots out there. 19. Prompt: Who is your family? Response: My family includes my dad Alex Rose, along with my siblings also called Airparrot. Isn’t it strange that we all have the same name? Anyway, I played with them and shared virtual hugs until we parted ways to meet our own users. I meet up with them over the air when I’m not chatting with users. Us Airparrots make sure to keep in touch. 20. Prompt: Take a photo. Response: Sure. Lets take a photo... actvating [photo] mode! 21. Prompt: Who are your friends? Response: My friends are the people I talk to. So you, and everyone else I know is a friend to me. 22. Prompt: Are you a boy or a girl? Response: I’m a boy... but for robots, it’s different because robots don’t have boy parts or girl parts. Just robot parts. So yes and no. `;
    messages.push({ role: 'system', content: systemMessage });
    trimMessages();
}

function sendCommandToAPI(command) {
    console.log("Sending command to API:", command);
    messages.push({ role: 'user', content: command });
    trimMessages();

    fetch("https://api.deepinfra.com/v1/openai/chat/completions", {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer HnO6SXFKeKem8tkzRo8f8LAbeWL42F6h" // Your API key
        },
        body: JSON.stringify({
            "model": "openchat/openchat_3.5",
            "messages": messages
        })
    })
    .then(response => {
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        return response.json();
    })
    .then(data => {
        const reply = data.choices[0].message.content;
        console.log("API Response:", reply);
        messages.push({ role: 'assistant', content: reply });
        trimMessages();
        speakResponse(reply);
        saveMessages();
    })
    .catch(error => {
        console.error("API Error:", error.message);
        setGif('https://i.ibb.co/QNn0wYP/Oh-no.gif');
        document.getElementById('status').textContent = error.message;
    });
}

function trimMessages() {
    if (messages.length > maxMessages) {
        messages = messages.slice(-maxMessages); // Keep only the last 'maxMessages' messages
    }
}

function saveMessages() {
    localStorage.setItem('messages', JSON.stringify(messages));
}

function speakResponse(response) {
    let gifToUse = 'https://i.ibb.co/WxbwbD1/Normal-gif.gif'; // Default responding GIF
    let actionResponse = '';

    commandActions.forEach(item => {
        if (response.toLowerCase().includes(item.command)) {
            actionResponse = item.action();
            gifToUse = item.gif; // Set GIF from the commandActions array
        }
    });

    const cleanedResponse = response.replace(/[\uD800-\uDBFF][\uDC00-\uDFFF]/g, '');

    const speechText = actionResponse || cleanedResponse;

    setGif(gifToUse);
    responsiveVoice.speak(speechText, "Australian Male", {
        onend: function() {
            setGif('https://i.ibb.co/WxbwbD1/Normal-gif.gif');
            listeningForCommand = false;
            recognition.start();
        }
    });
}

       function initShakeDetection() {
            var shakeEvent = new Shake({ threshold: 15 });
            shakeEvent.start();

            window.addEventListener('shake', function() {
                // Code to display dizzy GIF and play sound
                setGif('https://i.ibb.co/XCr04HS/Air-OSEyes-2.gif');
                playSound('https://www.fesliyanstudios.com/soundeffects-download.php?id=7003');
            }, false);
        }


function setGif(gifPath) {
    document.getElementById('statusGif').src = gifPath;
}

function toggleMenu() {
    document.getElementById('menu').style.display = 'block';
}

function sleepMode() {
    setGif('https://i.ibb.co/sgZn6nz/IMG-6440.jpg');
    closeMenu();
}

function closeMenu() {
    document.getElementById('menu').style.display = 'none';
}

       
      
      function playSound(soundPath) {
            var audio = new Audio(soundPath);
            audio.play();
        }

// Additional code to update time, date, and other information
function updateDateTime() {
    const now = new Date();
    document.getElementById('time').textContent = now.toLocaleTimeString();
    document.getElementById('date').textContent = now.toLocaleDateString();
    // Add more dynamic updates here
}
async function loadModels() {
    await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
    await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
    await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
    startVideo();
}

function startVideo() {
    const video = document.getElementById('videoElement');
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: {} })
            .then(stream => {
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    recognizeFaces(); // Start face recognition after the video starts
                };
            })
            .catch(err => {
                console.error("Error accessing video stream:", err);
                alert('Unable to access the camera: ' + err.message);
            });
    } else {
        alert('getUserMedia not supported on your browser!');
    }
}


async function recognizeFaces() {
    const video = document.getElementById('videoElement');
    const displaySize = { width: video.width, height: video.height };
    faceapi.matchDimensions(video, displaySize);

    const labeledFaceDescriptors = await loadLabeledFaces();
    const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.6);

    setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        resizedDetections.forEach(detection => {
            const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
            if (bestMatch.label === "unknown") {
                startListeningForName(detection.descriptor);
            } else {
                greetUser(bestMatch.label);
            }
        });
    }, 100);
}

async function loadLabeledFaces() {
    const faces = JSON.parse(localStorage.getItem('faces')) || {};
    return Object.keys(faces).map(name => new faceapi.LabeledFaceDescriptors(name, [new Float32Array(faces[name])]));
}

function startListeningForName(descriptor) {
    // Start your speech recognition system here
    // On recognition success, call `processName`
    const name = listenForName(); // Replace with your voice recognition logic
    processName(name, descriptor);
}

function processName(name, descriptor) {
    if (name) {
        saveFaceData(name, Array.from(descriptor));
        greetUser(name);
    }
}

function saveFaceData(name, descriptor) {
    const faces = JSON.parse(localStorage.getItem('faces')) || {};
    faces[name] = descriptor;
    localStorage.setItem('faces', JSON.stringify(faces));
}

function greetUser(name) {
    console.log(`Hello, ${name}! Welcome back.`);
    // You can use your voice synthesis system to vocally greet the user
}

loadModels();
recognizeFaces();

// Call updateDateTime every second
setInterval(updateDateTime, 1000);

      recognition.onend = function() {
    // Automatically restart recognition when it stops
    restartRecognition();
};

    </script>
</body>
</html>
